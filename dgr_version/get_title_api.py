"""
íƒ€ì´í‹€ ì¶”ì¶œ API
í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: ë¦¬ë­ì»¤ + ë ˆì´ì•„ì›ƒ ì ìˆ˜
"""
from flask import Flask, jsonify, request
import copy
import re
import numpy as np

app = Flask(__name__)

# ========== ìƒìˆ˜ ì •ì˜ ==========
# ê±°ë¦¬ ë° í•„í„°ë§ ê´€ë ¨
Y_LINE_TOLERANCE = 100  # ê°™ì€ ì¤„ë¡œ ê°„ì£¼í•  y ì¢Œí‘œ í—ˆìš© ì˜¤ì°¨ (px)
UP_MULTIPLIER = 1.5  # í‘œ ìœ„ìª½ íƒìƒ‰ ë²”ìœ„ (í‘œ ë†’ì´ì˜ ë°°ìˆ˜)
X_TOLERANCE = 800  # ìˆ˜í‰ ê·¼ì ‘ í—ˆìš© ê±°ë¦¬ (px)

# ML ëª¨ë¸ ê´€ë ¨
RERANKER_MODEL = "BAAI/bge-reranker-v2-m3"  # í¬ë¡œìŠ¤-ì¸ì½”ë” ë¦¬ë­ì»¤ (ë‹¤êµ­ì–´ SOTA)
EMBEDDER_MODEL = "BAAI/bge-m3"  # ì„ë² ë”© ëª¨ë¸ (1ì°¨ í•„í„°ë§ìš©)
E5_MODEL = "intfloat/multilingual-e5-large"  # E5 ì„ë² ë”© (ê´€ë ¨ì„± íŒë‹¨ìš©, query:/passage: í”„ë¡¬í”„íŠ¸ ì§€ì›)
ML_DEVICE = 0  # -1: CPU, 0: GPU
MAX_TEXT_INPUT_LENGTH = 512  # ML ëª¨ë¸ ì…ë ¥ ìµœëŒ€ ê¸¸ì´

# ëª¨ë¸ ì‚¬ìš© ì„¤ì •
USE_RERANKER = True   # ë¦¬ë­ì»¤ ì‚¬ìš© ì—¬ë¶€
USE_EMBEDDER_FILTER = False  # ì„ë² ë”© ê¸°ë°˜ 1ì°¨ í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€ (ë¦¬ë­ì»¤ë¡œ ì¶©ë¶„)
USE_E5_FILTER = True  # E5 ê¸°ë°˜ ê´€ë ¨ì„± í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€

SCORE_THRESHOLD = 0.30   # ì œëª© íŒì • ìµœì†Œ ì ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ 30% ì´ìƒ)
EMBEDDING_SIMILARITY_THRESHOLD = 0.3  # BGE ì„ë² ë”©: í‘œ ë¬¸ë§¥ê³¼ ìœ ì‚¬ë„ ìµœì†Œê°’
E5_SIMILARITY_THRESHOLD = 0.50  # E5 ì„ë² ë”©: query-passage ìœ ì‚¬ë„ ìµœì†Œê°’ (í•„í„°ë§ìš©)

# ë¦¬ë­ì»¤ ì„¤ì •
RERANKER_TEMPERATURE = 0.4  # ì˜¨ë„ ì†Œí”„íŠ¸ë§¥ìŠ¤ tau ê°’ (< 1 â†’ ëŒ€ë¹„ ê°•í™”)
RERANKER_BATCH_SIZE = 32    # ë¦¬ë­ì»¤ ë°°ì¹˜ í¬ê¸°


# íŒ¨í„´ ê´€ë ¨ ìƒìˆ˜
SUBTITLE_MIN_LENGTH = 4  # ì†Œì œëª© ìµœì†Œ ê¸¸ì´
SUBTITLE_MAX_LENGTH = 40  # ì†Œì œëª© ìµœëŒ€ ê¸¸ì´
CROSS_REF_MIN_LENGTH = 35  # êµì°¨ ì°¸ì¡° ìµœì†Œ ê¸¸ì´
LONG_SENTENCE_MIN_LENGTH = 40  # ê¸´ ì„¤ëª…ë¬¸ ìµœì†Œ ê¸¸ì´

# í…ìŠ¤íŠ¸ ì¶œë ¥ ê´€ë ¨
MAX_DISPLAY_TEXT_LENGTH = 50  # ì½˜ì†” ì¶œë ¥ ì‹œ í…ìŠ¤íŠ¸ ìµœëŒ€ ê¸¸ì´
MAX_CONTEXT_DISPLAY_LENGTH = 80  # í‘œ ë¬¸ë§¥ ì¶œë ¥ ì‹œ ìµœëŒ€ ê¸¸ì´
MAX_FILTER_DISPLAY = 3  # í•„í„°ë§ëœ í•­ëª© ìµœëŒ€ ì¶œë ¥ ê°œìˆ˜

# API ì„œë²„ ì„¤ì •
API_HOST = '0.0.0.0'
API_PORT = 5555
API_DEBUG = True

# ML ëª¨ë¸ ë³€ìˆ˜
reranker = None
embedder = None
e5_model = None

# ë””ë°”ì´ìŠ¤ ì„¤ì •
import torch

def _resolve_device():
    """ML_DEVICE ì„¤ì •ê³¼ CUDA ê°€ìš©ì„±ì— ë”°ë¼ ë””ë°”ì´ìŠ¤ ê²°ì •"""
    use_gpu = (ML_DEVICE == 0 and torch.cuda.is_available())
    return "cuda:0" if use_gpu else "cpu"

DEVICE_STR = _resolve_device()
print(f"â–¶ Inference device = {DEVICE_STR}")

# GPU ì„±ëŠ¥ ìµœì í™” (A100/RTX40 ê³„ì—´)
if DEVICE_STR.startswith("cuda"):
    torch.set_float32_matmul_precision("high")
    try:
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
    except Exception:
        pass

# ë¦¬ë­ì»¤ ëª¨ë¸ ë¡œë“œ
try:
    from sentence_transformers import CrossEncoder
    try:
        reranker = CrossEncoder(
            RERANKER_MODEL,
            device=DEVICE_STR,
            default_activation_function=None  # logits ëª¨ë“œ (softmax ë¯¸ì ìš©)
        )
    except TypeError:
        # ì¼ë¶€ êµ¬ë²„ì „ì€ ì¸ì ì—†ì´ë„ logits ë°˜í™˜ ê°€ëŠ¥
        reranker = CrossEncoder(RERANKER_MODEL, device=DEVICE_STR)
    print(f"âœ… ë¦¬ë­ì»¤ ë¡œë“œ ì™„ë£Œ ({RERANKER_MODEL}, device={DEVICE_STR})")
except ImportError:
    print("âš ï¸  sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ (CrossEncoder)")
    reranker = None
except Exception as e:
    print(f"âš ï¸  ë¦¬ë­ì»¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
    reranker = None

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (1ì°¨ í•„í„°ë§ìš©)
try:
    from sentence_transformers import SentenceTransformer
    embedder = SentenceTransformer(EMBEDDER_MODEL, device=DEVICE_STR)
    print(f"âœ… ì„ë² ë” ë¡œë“œ ì™„ë£Œ ({EMBEDDER_MODEL}, device={DEVICE_STR})")
except ImportError:
    print("âš ï¸  sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ (SentenceTransformer)")
    embedder = None
except Exception as e:
    print(f"âš ï¸  ì„ë² ë” ë¡œë“œ ì‹¤íŒ¨: {e}")
    embedder = None

# E5 ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ê´€ë ¨ì„± íŒë‹¨ìš©)
try:
    from sentence_transformers import SentenceTransformer
    e5_model = SentenceTransformer(E5_MODEL, device=DEVICE_STR)
    print(f"âœ… E5 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({E5_MODEL}, device={DEVICE_STR})")
except ImportError:
    print("âš ï¸  sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ (E5)")
    e5_model = None
except Exception as e:
    print(f"âš ï¸  E5 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    e5_model = None

# ========== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ==========
def clean_text(s: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ë¦¬"""
    return re.sub(r"\s+", " ", s).strip()

def clamp_text_len(s: str, max_chars=MAX_TEXT_INPUT_LENGTH):
    """í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ"""
    s = clean_text(s)
    return s[:max_chars] if len(s) > max_chars else s


def is_trivial(text: str) -> bool:
    """ë¬´ì˜ë¯¸í•œ í…ìŠ¤íŠ¸ í•„í„°ë§ (í˜ì´ì§€ ë²ˆí˜¸, ì €ì‘ê¶Œ ë“±)"""
    s = text.strip()

    # 1~3ìë¦¬ ìˆ«ìë§Œ
    if re.fullmatch(r"\d{1,3}", s):
        return True

    # ì €ì‘ê¶Œ í‘œì‹œ
    if "all rights reserved" in s.lower():
        return True
    if s.startswith("Â©"):
        return True

    # ë„ˆë¬´ ì§§ìŒ
    if len(s) <= 2:
        return True

    # ìˆ«ìë§Œ í¬í•¨
    if re.match(r'^[\d\s\.\-]+$', s):
        return True

    # íŠ¹ìˆ˜ë¬¸ìë§Œ
    if len(re.sub(r"[\W_]+", "", s)) <= 1:
        return True

    return False

def iou_1d(a: tuple, b: tuple) -> float:
    """1ì°¨ì› IoU (ìˆ˜í‰ ê²¹ì¹¨ ê³„ì‚°)"""
    overlap = max(0, min(a[1], b[1]) - max(a[0], b[0]))
    union = (a[1] - a[0]) + (b[1] - b[0]) - overlap
    return overlap / union if union > 0 else 0.0

def horizontally_near(table_x: tuple, text_x: tuple, tol: int = X_TOLERANCE) -> bool:
    """ìˆ˜í‰ìœ¼ë¡œ ê²¹ì¹˜ê±°ë‚˜ ê·¼ì ‘í•œì§€ í™•ì¸"""
    if iou_1d(table_x, text_x) > 0:
        return True
    return (text_x[1] >= table_x[0] - tol and text_x[0] <= table_x[1] + tol)

# ========== íŒ¨í„´ ìŠ¤ì½”ì–´/í˜ë„í‹° ==========
UNIT_TOKENS = ["ë‹¨ìœ„", "unit", "u.", "â„ƒ", "Â°c", "%", "mm", "kg", "km", "ì›", "ê°œ", "íšŒ"]

# ì†Œì œëª©/ì„¹ì…˜ íŒ¨í„´
CIRCLED_RX = r"[\u2460-\u2473\u3251-\u325F]"  # â‘ -â‘³, 21-35
BULLET_RX = r"[â€¢âˆ™Â·\-â€“â€”]"  # ë¶ˆë¦¿/ëŒ€ì‹œ
PAREN_NUM_RX = r"\(?\d{1,2}\)?[.)]"  # (1) 1) 1.

def is_subtitle_like(s: str) -> bool:
    """í…Œì´ë¸” ë°”ë¡œ ìœ„ì— ìì£¼ ì˜¤ëŠ” 'ì†Œì œëª©' íŒ¨í„´:
    - â‘  â‘¡ â€¦ / (1) 1) 1. / â€¢ - ë“± ë¶ˆë¦¿ ì‹œì‘
    - ê¸¸ì´ ì œí•œ í™•ì¸
    """
    t = s.strip()
    if re.match(rf"^({CIRCLED_RX}|{PAREN_NUM_RX}|{BULLET_RX})\s*\S+", t):
        if SUBTITLE_MIN_LENGTH <= len(t) <= SUBTITLE_MAX_LENGTH:
            return True

    # 'ã…‡ ì œëª©' í˜•ì‹ë„ ì¶”ê°€ - ë‹¨, ë„ˆë¬´ ì§§ê±°ë‚˜ ë¶ˆì™„ì „í•œ ë¬¸ì¥ì€ ì œì™¸
    if re.match(r"^[ã…‡o]\s+\S{2,}", t) and len(t) <= SUBTITLE_MAX_LENGTH:
        # "ã…‡ ìš”êµ¬ì‚¬í•­", "ã…‡ ì œì•½" ê°™ì€ ë¶ˆì™„ì „í•œ ì œëª© ì œì™¸
        incomplete_patterns = [
            r"^[ã…‡o]\s+(ìš”êµ¬ì‚¬í•­|ì œì•½|ì¡°ê±´|ì‚¬í•­)$",  # ë„ˆë¬´ ì§§ìŒ
            r"^[ã…‡o]\s+ì œì•½\s*ìš”êµ¬ì‚¬í•­$",  # "ã…‡ ì œì•½ ìš”êµ¬ì‚¬í•­" (ë¬¸ë§¥ ì—†ìŒ)
        ]
        for pattern in incomplete_patterns:
            if re.search(pattern, t):
                return False
        return True

    return False

def is_unit_like(s: str) -> bool:
    """ë‹¨ìœ„ í‘œê¸° ë¼ì¸ íŒë³„"""
    t = s.strip().lower()
    # [ë‹¨ìœ„: â„ƒ], (ë‹¨ìœ„ : %), <ë‹¨ìœ„: mm> ë“±
    if re.match(r"^[\[\(\<]?\s*(ë‹¨ìœ„|unit)\s*[:ï¼š]?\s*[\w%Â°â„ƒãœ\-/]+[\]\)\>]?\s*$", t):
        return True
    # ê¸¸ì´ ì•„ì£¼ ì§§ê³ (<=12) ìœ ë‹› í† í°ë§Œ ìˆëŠ” ê²½ìš°
    if len(t) <= 12 and any(tok in t for tok in UNIT_TOKENS):
        letters = re.sub(r"[^ê°€-í£a-zA-Z]", "", t)
        return len(letters) <= 1
    return False

def is_table_title_like(s: str) -> bool:
    """í‘œ ì œëª© íŒ¨í„´ íŒë³„"""
    t = s.strip()

    # 1. 'í‘œ B.8 ì›”ë³„ ê¸°ì˜¨', 'í‘œ A.6 í† ì§€ì´ìš©í˜„í™©', 'í‘œ B .4' (ê³µë°± í¬í•¨), 'í‘œ 3-2 ì—°ê°„ ì‹¤ì ' ë“±
    if re.search(r"^í‘œ\s*[A-Za-z]?\s*[\.\-]?\s*\d+([\-\.]\d+)?", t):
        return True

    # 2. 'â–¡ ì¶”ì§„ì¡°ì§ êµ¬ì„±', 'â–  ì‚¬ì—…ê°œìš”' ë“± (ë°•ìŠ¤ ê¸°í˜¸ + ì œëª©)
    if re.search(r"^[â–¡â– â—†â—‡â–ªâ–«â—â—‹â—‰â—]\s*\S", t):
        return True

    # 3. '<í‘œ ì œëª©>', 'ã€í‘œ ì œëª©ã€‘' ë“±
    if re.search(r"^[<ã€Š\[ã€\(]\s*í‘œ?\s*\d*\s*[\]ã€‘\)>ã€‹]", t):
        return True

    # 4. ì„¹ì…˜/í‘œ ì œëª© í˜•íƒœ(ìˆ«ì.ìˆ«ì ì œëª©) - ë‹¨, ë„ˆë¬´ ì§§ì§€ ì•Šì•„ì•¼ í•¨
    if re.search(r"^\d+(\.\d+){0,2}\s+\S{3,}", t) and len(t) <= 50:
        return True

    return False

def is_cross_reference(s: str) -> bool:
    """êµì°¨ ì°¸ì¡°/ì„¤ëª… ë¬¸ì¥ íŒë³„"""
    t = s.strip().replace(" ", "")

    # 'í‘œ A.20ì—ì˜í•˜ë©´', 'í‘œ B .4ì—ì„œ', 'í‘œ 3.2ì—ë”°ë¥´ë©´' ë“± (í‘œ ë²ˆí˜¸ë¡œ ì‹œì‘í•˜ëŠ” ì°¸ì¡° ë¬¸ì¥)
    if re.search(r"^í‘œ[A-Za-z]?[\.\-]?\d+([\-\.]\d+)?(ì—ì˜í•˜ë©´|ì—ë”°ë¥´ë©´|ì—ì„œ|ì„ë³´ë©´|ì—ë‚˜íƒ€ë‚œ|ì—ì„œì™€ê°™ì´|ê³¼ê°™ì´)", t):
        return True

    # 'ìƒì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒ í‘œ B.12ì™€ ê°™ë‹¤' ë¥˜
    if re.search(r"(ë‹¤ìŒí‘œ|í•˜ê¸°í‘œ|ë³¸í‘œ|ì•„ë˜í‘œ)[A-Za-z]?\d+.*(ê°™ë‹¤|ë‚˜íƒ€ë‚¸ë‹¤|ë³´ì¸ë‹¤|ì •ë¦¬|ì°¸ì¡°)", t):
        return True

    # 'ìƒì„¸í•œë‚´ìš©ì€ë‹¤ìŒí‘œB.12ì™€ê°™ë‹¤' ê°™ì´ ë¶™ì–´ì“´ OCRë„ ì»¤ë²„
    if re.search(r"(ìƒì„¸í•œë‚´ìš©|ìì„¸í•œë‚´ìš©).*(ë‹¤ìŒí‘œ|ì•„ë˜í‘œ).*(ê°™ë‹¤|ë‚˜íƒ€ë‚œë‹¤|ì°¸ì¡°)", t):
        return True

    # ëª…í™•í•œ ì„¤ëª… ë¬¸ì¥ë§Œ (ë™ì‚¬ ì–´ë¯¸ë¡œ ëë‚˜ëŠ” ê¸´ ë¬¸ì¥)
    if len(t) >= CROSS_REF_MIN_LENGTH and re.search(r"(ë°”ëë‹ˆë‹¤|ë°”ë€ë‹¤|í˜‘ì˜ëŒ€ë¡œ|ì•ˆë‚´í•˜|ìš”ì²­)", t):
        return True

    # 'â€»' ì‹œì‘í•˜ëŠ” ì£¼ì„/ë¶€ê°€ì„¤ëª…
    if t.startswith("â€»") and len(t) >= 20:
        return True

    return False

# ========== bbox ì¶”ì¶œ ==========
def get_bbox_from_text(text):
    """text ê°ì²´ì—ì„œ bbox ì •ë³´ ì¶”ì¶œ [l, t, r, b] í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
    if 'rect' in text and isinstance(text['rect'], list) and len(text['rect']) >= 4:
        return text['rect']
    elif 'bbox' in text and isinstance(text['bbox'], list) and len(text['bbox']) >= 4:
        return text['bbox']
    elif 'bbox' in text and isinstance(text['bbox'], dict):
        bbox = text['bbox']
        return [bbox.get('l', 0), bbox.get('t', 0), bbox.get('r', 0), bbox.get('b', 0)]
    elif 'merged_bbox' in text:
        return text['merged_bbox']
    return None

def get_bbox_from_table(table):
    """table ê°ì²´ì—ì„œ bbox ì •ë³´ ì¶”ì¶œ [l, t, r, b] í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
    if 'bbox' in table and isinstance(table['bbox'], list) and len(table['bbox']) >= 4:
        return table['bbox']
    elif 'bbox' in table and isinstance(table['bbox'], dict):
        bbox = table['bbox']
        return [bbox.get('l', 0), bbox.get('t', 0), bbox.get('r', 0), bbox.get('b', 0)]
    return None

# ========== í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë³‘í•© ==========
def extract_text_content(text_obj):
    """text ê°ì²´ì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    if 'merged_text' in text_obj:
        return text_obj['merged_text']

    if 't' in text_obj and isinstance(text_obj['t'], list) and len(text_obj['t']) > 0:
        t_items = text_obj['t']
        sorted_items = sorted(t_items, key=lambda item: item.get('tid', 0))
        texts = []
        for t_item in sorted_items:
            if 'text' in t_item:
                texts.append(t_item['text'])
        if texts:
            return ' '.join(texts)  # ê³µë°±ìœ¼ë¡œ ì—°ê²°

    if 'text' in text_obj:
        return text_obj['text']
    elif 'v' in text_obj:
        return text_obj['v']
    return ""

def flatten_text_objects(texts):
    """paraIndexë¡œ ê·¸ë£¹í™”ëœ í…ìŠ¤íŠ¸ë¥¼ ê°œë³„ 't' ìš”ì†Œë¡œ ë¶„í•´"""
    flattened = []
    for text_obj in texts:
        if 't' in text_obj and isinstance(text_obj['t'], list):
            for t_item in text_obj['t']:
                if 'bbox' in t_item and 'text' in t_item:
                    flattened.append({
                        'bbox': t_item['bbox'],
                        'text': t_item['text'],
                        'tid': t_item.get('tid', 0)
                    })
        else:
            flattened.append(text_obj)
    return flattened

def group_texts_by_line(texts, y_tolerance=Y_LINE_TOLERANCE):
    """ê°™ì€ ì¤„ì˜ í…ìŠ¤íŠ¸ë“¤ì„ ê·¸ë£¹í™”"""
    if not texts:
        return []

    flattened = flatten_text_objects(texts)
    sorted_texts = sorted(flattened, key=lambda t: get_bbox_from_text(t)[1] if get_bbox_from_text(t) else float('inf'))

    grouped = []
    current_group = []
    group_y_min = None

    for text in sorted_texts:
        bbox = get_bbox_from_text(text)
        if not bbox:
            continue

        y_center = (bbox[1] + bbox[3]) / 2

        if group_y_min is None or abs(y_center - group_y_min) <= y_tolerance:
            current_group.append(text)
            if group_y_min is None:
                group_y_min = y_center
        else:
            if current_group:
                merged = merge_text_group(current_group)
                if merged:
                    grouped.append(merged)
            current_group = [text]
            group_y_min = y_center

    if current_group:
        merged = merge_text_group(current_group)
        if merged:
            grouped.append(merged)

    grouped.sort(key=lambda g: g.get('merged_bbox', [0, 0, 0, 0])[1] if g else float('inf'))
    return grouped

def merge_text_group(text_group):
    """ê°™ì€ ì¤„ì˜ í…ìŠ¤íŠ¸ë“¤ì„ x ì¢Œí‘œ ìˆœì„œëŒ€ë¡œ ë³‘í•©"""
    if not text_group:
        return None

    sorted_group = sorted(text_group, key=lambda t: get_bbox_from_text(t)[0] if get_bbox_from_text(t) else 0)

    text_parts = []
    prev_bbox = None

    for t in sorted_group:
        text_content = extract_text_content(t)
        if not text_content:
            continue

        current_bbox = get_bbox_from_text(t)

        # í…ìŠ¤íŠ¸ ì¡°ê° ì‚¬ì´ì— í•­ìƒ ê³µë°± ì¶”ê°€ (ì²« ì¡°ê° ì œì™¸)
        if prev_bbox and current_bbox:
            text_parts.append(' ')

        text_parts.append(text_content)
        prev_bbox = current_bbox

    merged_text = ''.join(text_parts)

    bboxes = [get_bbox_from_text(t) for t in sorted_group]
    bboxes = [b for b in bboxes if b]

    if not bboxes:
        return None

    merged_bbox = [
        min(b[0] for b in bboxes),
        min(b[1] for b in bboxes),
        max(b[2] for b in bboxes),
        max(b[3] for b in bboxes)
    ]

    merged_obj = text_group[0].copy() if text_group else {}
    merged_obj['merged_text'] = merged_text
    merged_obj['merged_bbox'] = merged_bbox

    return merged_obj

# ========== í›„ë³´ ìˆ˜ì§‘ ==========
def collect_candidates_for_table(table, texts, all_tables=None):
    """í‘œ ìœ„/ì•„ë˜ìª½ì— ìˆëŠ” í…ìŠ¤íŠ¸ í›„ë³´ ìˆ˜ì§‘ (ê·œì¹™ ê¸°ë°˜ í•„í„°ë§)"""
    table_bbox = get_bbox_from_table(table)
    if not table_bbox:
        return []

    tbx1, tby1, tbx2, tby2 = table_bbox
    h = tby2 - tby1
    y_min_up = max(0, tby1 - int(UP_MULTIPLIER * h))  # ìœ„ìª½ íƒìƒ‰ ë²”ìœ„
    y_max_down = tby2 + int(UP_MULTIPLIER * h)  # ì•„ë˜ìª½ íƒìƒ‰ ë²”ìœ„

    # ê·¸ë£¹í™”ëœ í…ìŠ¤íŠ¸
    grouped_texts = group_texts_by_line(texts, y_tolerance=Y_LINE_TOLERANCE)

    candidates = []
    for text in grouped_texts:
        if not text:
            continue

        text_bbox = text.get('merged_bbox') or get_bbox_from_text(text)
        if not text_bbox:
            continue

        px1, py1, px2, py2 = text_bbox

        # í‘œ ìœ„ìª½ ë˜ëŠ” ì•„ë˜ìª½ì— ìˆëŠ”ì§€ í™•ì¸
        is_above = (py2 <= tby1 and py1 >= y_min_up)
        is_below = (py1 >= tby2 and py2 <= y_max_down)

        if not (is_above or is_below):
            continue

        # ìˆ˜í‰ìœ¼ë¡œ ê²¹ì¹˜ê±°ë‚˜ ê·¼ì ‘í•œì§€ í™•ì¸
        if not horizontally_near((tbx1, tbx2), (px1, px2), tol=X_TOLERANCE):
            continue

        text_content = clean_text(text.get('merged_text') or extract_text_content(text))

        # ë¬´ì˜ë¯¸í•œ í…ìŠ¤íŠ¸ í•„í„°ë§
        if not text_content or is_trivial(text_content):
            continue

        candidates.append({
            'text': text_content,
            'bbox': text_bbox
        })

    # ì¤‘ë³µ ì œê±°
    unique = {}
    for c in candidates:
        unique.setdefault(c['text'], c)

    return list(unique.values())

# ========== í‘œ ë¬¸ë§¥ êµ¬ì¶• ==========
def build_table_context(table, max_cells=10):
    """í‘œì˜ í—¤ë”ì™€ ì²« í–‰ìœ¼ë¡œ ë¬¸ë§¥ êµ¬ì¶•"""
    headers = []
    if 'rows' in table and table['rows']:
        for cell in table['rows'][0]:
            cell_texts = [t['v'] for t in cell.get('texts', []) if t.get('v')]
            if cell_texts:
                headers.append(clean_text(" ".join(cell_texts)))

    header_str = " | ".join(headers[:max_cells]) if headers else ""

    first_row = []
    if 'rows' in table and len(table['rows']) >= 2:
        for cell in table['rows'][1]:
            cell_texts = [t['v'] for t in cell.get('texts', []) if t.get('v')]
            if cell_texts:
                first_row.append(clean_text(" ".join(cell_texts)))

    first_row_str = " | ".join(first_row[:max_cells]) if first_row else ""

    parts = []
    if header_str:
        parts.append(f"í—¤ë”: {header_str}")
    if first_row_str:
        parts.append(f"ì²«í–‰: {first_row_str}")

    return " / ".join(parts) if parts else "í‘œ ì •ë³´ ì—†ìŒ"

# ========== ML ìŠ¤ì½”ì–´ë§ ==========
def make_reranker_pair(cand_text: str, table_ctx: str):
    """ë¦¬ë­ì»¤ ì…ë ¥ ìŒ ìƒì„± (ì œëª©-í‘œ ê´€ê³„ ëª…ì‹œ)"""
    query = clamp_text_len(cand_text, max_chars=100)
    context = clamp_text_len(table_ctx, max_chars=600)

    # ëª…í™•í•œ ì œëª© íŒì • ì§ˆë¬¸
    query_formatted = f"í‘œ ì œëª©: {query}"
    context_formatted = f"ì´ê²ƒì€ ì˜¬ë°”ë¥¸ í‘œ ì œëª©ì¸ê°€?\n\ní‘œ ë‚´ìš©:\n{context}"

    return (query_formatted, context_formatted)

def reranker_logits_batch(pairs):
    """ë°°ì¹˜ ë¦¬ë­ì»¤ ë¡œì§“ ë°˜í™˜
    pairs: [(cand_text, table_ctx), ...]
    ë°˜í™˜: numpy array of logits (float)
    """
    import numpy as np
    if not reranker or not pairs:
        return np.zeros((len(pairs),), dtype=float)
    try:
        out = reranker.predict(pairs, convert_to_numpy=True, batch_size=RERANKER_BATCH_SIZE)
        logits = np.asarray(out).reshape(-1)

        # ë””ë²„ê¹…: ë¡œì§“ ì¶œë ¥
        for i, (pair, logit) in enumerate(zip(pairs, logits)):
            cand_text = pair[0].replace("[í‘œì œëª© í›„ë³´] ", "")[:30]
            print(f"      [RR-DEBUG] '{cand_text}' â†’ logit={logit:.3f}")

        return logits
    except Exception as e:
        print(f"  ë¦¬ë­ì»¤ ì˜¤ë¥˜: {e}")
        return np.zeros((len(pairs),), dtype=float)

def softmax_with_temp_from_logits(logits, tau=RERANKER_TEMPERATURE):
    """ë¡œì§“ì— ì˜¨ë„ë¥¼ ì ìš©í•œ ì†Œí”„íŠ¸ë§¥ìŠ¤ (í›„ë³´ ì§‘í•© ë‚´ ëŒ€ë¹„ â†‘)"""
    import numpy as np
    x = np.asarray(logits, dtype=float) / max(tau, 1e-6)
    x = x - x.max()  # overflow ë°©ì§€
    ex = np.exp(x)
    return ex / (ex.sum() + 1e-12)


def filter_candidates_by_embedding(candidates, table_ctx):
    """ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ 1ì°¨ í•„í„°ë§: í‘œ ë¬¸ë§¥ê³¼ ê´€ë ¨ ìˆëŠ” í›„ë³´ë§Œ ë‚¨ê¹€"""
    import numpy as np

    if not embedder or not candidates:
        return candidates

    try:
        # í‘œ ë¬¸ë§¥ ì„ë² ë”©
        ctx_embedding = embedder.encode(table_ctx, convert_to_numpy=True, normalize_embeddings=True)

        # í›„ë³´ í…ìŠ¤íŠ¸ ì„ë² ë”©
        candidate_texts = [c['text'] for c in candidates]
        candidate_embeddings = embedder.encode(candidate_texts, convert_to_numpy=True, normalize_embeddings=True)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì •ê·œí™”ëœ ë²¡í„°ë¼ì„œ ë‚´ì ë§Œ í•˜ë©´ ë¨)
        similarities = np.dot(candidate_embeddings, ctx_embedding)

        # threshold ì´ìƒì¸ í›„ë³´ë§Œ ë‚¨ê¹€
        filtered = []
        for i, c in enumerate(candidates):
            if similarities[i] >= EMBEDDING_SIMILARITY_THRESHOLD:
                filtered.append(c)
                print(f"    [EMB] '{c['text'][:30]}' â†’ sim={similarities[i]:.3f} âœ“")
            else:
                print(f"    [EMB] '{c['text'][:30]}' â†’ sim={similarities[i]:.3f} âœ— (ì œì™¸)")

        return filtered if filtered else candidates  # ëª¨ë‘ í•„í„°ë§ë˜ë©´ ì›ë³¸ ë°˜í™˜

    except Exception as e:
        print(f"  ì„ë² ë”© í•„í„°ë§ ì˜¤ë¥˜: {e}")
        return candidates

def filter_candidates_by_e5(candidates, table_ctx):
    """E5 ì„ë² ë”© ê¸°ë°˜ ê´€ë ¨ì„± í•„í„°ë§ ë° ìˆœìœ„ ê²°ì •

    E5 ëª¨ë¸ì˜ query:/passage: í”„ë¡¬í”„íŠ¸ë¥¼ í™œìš©í•˜ì—¬
    í›„ë³´ ì œëª©ê³¼ í‘œ ë‚´ìš© ê°„ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê³ 
    ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ í›„ë³´ë¥¼ ë°˜í™˜
    """
    if not e5_model or not candidates:
        return candidates

    try:
        import numpy as np

        # í‘œ ë¬¸ë§¥ ì„ë² ë”© (ì–‘ë°©í–¥)
        # ë°©ë²• 1: í‘œ â†’ passage
        passage_text = f"passage: {table_ctx[:400]}"
        passage_emb = e5_model.encode(passage_text, convert_to_numpy=True, normalize_embeddings=True)

        # ë°©ë²• 2: í‘œ â†’ query (ì—­ë°©í–¥ ë¹„êµë¥¼ ìœ„í•´)
        table_as_query = f"query: {table_ctx[:400]}"
        table_query_emb = e5_model.encode(table_as_query, convert_to_numpy=True, normalize_embeddings=True)

        # ëª¨ë“  í›„ë³´ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ì–‘ë°©í–¥)
        scored_candidates = []
        for c in candidates:
            cand_text = c['text'][:120]

            # ë°©ë²• 1: í›„ë³´(query) â†’ í‘œ(passage)
            query_text = f"query: {cand_text}"
            query_emb = e5_model.encode(query_text, convert_to_numpy=True, normalize_embeddings=True)
            sim1 = float(np.dot(query_emb, passage_emb))

            # ë°©ë²• 2: í›„ë³´(passage) â†’ í‘œ(query) - ì—­ë°©í–¥
            cand_as_passage = f"passage: {cand_text}"
            cand_passage_emb = e5_model.encode(cand_as_passage, convert_to_numpy=True, normalize_embeddings=True)
            sim2 = float(np.dot(table_query_emb, cand_passage_emb))

            # ì–‘ë°©í–¥ í‰ê·  (ëŒ€ì¹­ì  ìœ ì‚¬ë„)
            similarity = (sim1 + sim2) / 2.0

            # í›„ë³´ì— E5 ì ìˆ˜ ì¶”ê°€
            c_with_score = c.copy()
            c_with_score['e5_score'] = similarity
            scored_candidates.append((c_with_score, similarity))

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        scored_candidates.sort(key=lambda x: -x[1])

        # ì ìˆ˜ ì¶œë ¥
        print("\n  [E5 ë‹¨ë… íŒë‹¨] í›„ë³´ ì ìˆ˜:")
        for c, sim in scored_candidates:
            cand_text = c['text'][:50]
            print(f"    '{cand_text}' â†’ sim={sim:.3f}")

        # ìµœê³  ì ìˆ˜ í›„ë³´ë§Œ ë°˜í™˜ (ì„ê³„ê°’ ì²´í¬)
        best_candidate, best_score = scored_candidates[0]

        if best_score >= E5_SIMILARITY_THRESHOLD:
            print(f"\n  âœ… E5 ì„ íƒ: '{best_candidate['text']}' (ì ìˆ˜: {best_score:.3f})")
            return [best_candidate]
        else:
            print(f"\n  âš ï¸  ìµœê³  ì ìˆ˜({best_score:.3f})ê°€ ì„ê³„ê°’({E5_SIMILARITY_THRESHOLD}) ë¯¸ë§Œ")
            return candidates  # ì„ê³„ê°’ ë¯¸ë‹¬ ì‹œ ëª¨ë‘ ë°˜í™˜

    except Exception as e:
        print(f"  E5 í•„í„°ë§ ì˜¤ë¥˜: {e}")
        return candidates

def build_table_context_rich(table, max_rows=6, max_cells_per_row=10):
    """í‘œ ë¬¸ë§¥ êµ¬ì¶• (ë” ë§ì€ í–‰ í¬í•¨) - ë¦¬ë­ì»¤ìš©"""
    all_rows = []

    if 'rows' in table and table['rows']:
        # ìµœëŒ€ max_rowsê°œ í–‰ ì¶”ì¶œ
        for row_idx, row in enumerate(table['rows'][:max_rows]):
            row_texts = []
            for cell in row[:max_cells_per_row]:
                cell_texts = [t['v'] for t in cell.get('texts', []) if t.get('v')]
                if cell_texts:
                    row_texts.append(clean_text(" ".join(cell_texts)))

            if row_texts:
                # ì²« í–‰ì€ í—¤ë”ë¡œ í‘œì‹œ
                if row_idx == 0:
                    all_rows.append("[í—¤ë”] " + " | ".join(row_texts))
                else:
                    all_rows.append(f"[í–‰{row_idx}] " + " | ".join(row_texts))

    return "\n".join(all_rows) if all_rows else "í‘œ ì •ë³´ ì—†ìŒ"

def build_table_context_full(table):
    """í‘œ ì „ì²´ ë‚´ìš© êµ¬ì¶• - ì„ë² ë”© í•„í„°ë§ìš©"""
    all_texts = []

    if 'rows' in table and table['rows']:
        for row in table['rows']:
            row_texts = []
            for cell in row:
                cell_texts = [t['v'] for t in cell.get('texts', []) if t.get('v')]
                if cell_texts:
                    row_texts.append(clean_text(" ".join(cell_texts)))
            if row_texts:
                all_texts.append(" | ".join(row_texts))

    return " / ".join(all_texts) if all_texts else "í‘œ ì •ë³´ ì—†ìŒ"

def score_candidates_with_logits(candidates, table_ctx, table_bbox):
    """ë¦¬ë­ì»¤ + íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ìŠ¤ì½”ì–´ë§"""
    import numpy as np

    # ë¦¬ë­ì»¤: í›„ë³´ ì§‘í•© ë‚´ ìƒëŒ€ ìˆœìœ„
    pairs = [make_reranker_pair(c['text'], table_ctx) for c in candidates]
    logits = reranker_logits_batch(pairs) if USE_RERANKER else np.zeros(len(candidates))
    rer_prob = softmax_with_temp_from_logits(logits)

    scored = []
    for i, c in enumerate(candidates):
        txt, bb = c['text'], c['bbox']

        # íœ´ë¦¬ìŠ¤í‹± ì ìˆ˜ ê³„ì‚°
        heuristic_score = 0.0
        pattern_bonus = 0.0

        # 1. í‘œ ì œëª© íŒ¨í„´ ("í‘œ 4.21 ...", "â–¡ ì œëª©" í˜•ì‹)
        if is_table_title_like(txt):
            pattern_bonus = 0.7

        # 2. ì†Œì œëª© íŒ¨í„´ (â‘  â‘¡ (1) ã…‡ ë“±)
        elif is_subtitle_like(txt):
            pattern_bonus = 0.4

        # 3. ì¼ë°˜ì ì¸ ì œëª© í˜•ì‹ì´ì§€ë§Œ ì ìˆ˜ëŠ” ë‚®ê²Œ
        elif len(txt) >= 5 and len(txt) <= 40:
            pattern_bonus = 0.2

        # 4. ìœ„ì¹˜ ì ìˆ˜ (í‘œ ìœ„ìª½ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ìŒ)
        distance = abs(bb[3] - table_bbox[1])  # í…ìŠ¤íŠ¸ í•˜ë‹¨ ~ í‘œ ìƒë‹¨ ê±°ë¦¬
        position_bonus = 0.0
        if distance < 50:  # 50px ì´ë‚´
            position_bonus = 0.25
        elif distance < 150:  # 150px ì´ë‚´
            position_bonus = 0.18
        elif distance < 300:  # 300px ì´ë‚´
            position_bonus = 0.1

        # 5. ê¸¸ì´ ì ìˆ˜ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ì§€ ì•Šì€ ê²ƒ ì„ í˜¸)
        txt_len = len(txt.strip())
        length_bonus = 0.0
        if 10 <= txt_len <= 50:
            length_bonus = 0.15
        elif 6 <= txt_len < 10:
            length_bonus = 0.05
        elif 50 < txt_len <= 70:
            length_bonus = 0.08

        heuristic_score = pattern_bonus + position_bonus + length_bonus

        # ìµœì¢… ì ìˆ˜ = ë¦¬ë­ì»¤(80%) + íœ´ë¦¬ìŠ¤í‹±(20%)
        final = float(rer_prob[i]) * 0.80 + heuristic_score * 0.20

        scored.append({
            "text": txt, "bbox": bb, "score": final,
            "details": {
                "reranker": float(rer_prob[i]),
                "heuristic": heuristic_score
            }
        })
    return scored

# ========== ë©”ì¸ ë¡œì§ ==========
def find_title_for_table(table, texts, all_tables=None, used_titles=None):
    """í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ í‘œ ì œëª© ì°¾ê¸°"""
    table_bbox = get_bbox_from_table(table)
    if not table_bbox:
        print("  í…Œì´ë¸” bbox ì—†ìŒ")
        return "", None

    print(f"  í…Œì´ë¸” bbox: y={table_bbox[1]}")

    if used_titles is None:
        used_titles = set()

    # Step 1: í›„ë³´ ìˆ˜ì§‘ (ê·œì¹™ ê¸°ë°˜ í•„í„°ë§)
    candidates = collect_candidates_for_table(table, texts, all_tables)

    # ì´ë¯¸ ì‚¬ìš©ëœ ì œëª© ì œì™¸
    candidates = [c for c in candidates if c['text'] not in used_titles]

    print(f"  í›„ë³´ ìˆ˜ì§‘: {len(candidates)}ê°œ")

    if not candidates:
        print("  âŒ í›„ë³´ ì—†ìŒ")
        return "", None

    # Step 2: í‘œ ë¬¸ë§¥ êµ¬ì¶•
    table_ctx = build_table_context_rich(table)
    print(f"  í‘œ ë¬¸ë§¥: {table_ctx[:MAX_CONTEXT_DISPLAY_LENGTH]}")

    # Step 2.5: ì„ë² ë”© ê¸°ë°˜ 1ì°¨ í•„í„°ë§ (í‘œ ì „ì²´ ë‚´ìš©ê³¼ ê´€ë ¨ ìˆëŠ” í›„ë³´ë§Œ)
    if USE_EMBEDDER_FILTER and embedder and len(candidates) > 3:
        before_filter = len(candidates)
        table_full_ctx = build_table_context_full(table)  # ì „ì²´ í‘œ ë‚´ìš©
        candidates = filter_candidates_by_embedding(candidates, table_full_ctx)
        print(f"  ì„ë² ë”© í•„í„°ë§: {before_filter}â†’{len(candidates)}ê°œ")

        if not candidates:
            print("  âŒ í•„í„°ë§ í›„ í›„ë³´ ì—†ìŒ")
            return "", None

    # Step 2.7: E5 ê¸°ë°˜ ê´€ë ¨ì„± í•„í„°ë§ (í‘œì™€ ê´€ë ¨ìˆëŠ” í›„ë³´ë§Œ ë‚¨ê¹€)
    if USE_E5_FILTER and e5_model and len(candidates) >= 2:
        before_filter = len(candidates)

        # E5 í•„í„°ë§ (í•„í„° ëª¨ë“œë¡œ ë³€ê²½)
        try:
            import numpy as np

            passage_text = f"passage: {table_ctx[:400]}"
            passage_emb = e5_model.encode(passage_text, convert_to_numpy=True, normalize_embeddings=True)

            filtered = []
            for c in candidates:
                cand_text = c['text'][:120]
                query_text = f"query: {cand_text}"
                query_emb = e5_model.encode(query_text, convert_to_numpy=True, normalize_embeddings=True)
                similarity = float(np.dot(query_emb, passage_emb))

                if similarity >= E5_SIMILARITY_THRESHOLD:
                    filtered.append(c)
                    print(f"    [E5] '{cand_text[:30]}' â†’ sim={similarity:.3f} âœ“")
                else:
                    print(f"    [E5] '{cand_text[:30]}' â†’ sim={similarity:.3f} âœ—")

            candidates = filtered if filtered else candidates
            print(f"  E5 í•„í„°ë§: {before_filter}â†’{len(candidates)}ê°œ")
        except Exception as e:
            print(f"  E5 í•„í„°ë§ ì˜¤ë¥˜: {e}")

        if not candidates:
            print("  âŒ E5 í•„í„°ë§ í›„ í›„ë³´ ì—†ìŒ")
            return "", None

    # Step 2.9: ìœ ë‹› í›„ë³´ ì‚­ì œ
    if any(is_table_title_like(c['text']) for c in candidates):
        candidates = [c for c in candidates if not is_unit_like(c['text'])]
        print(f"  ìœ ë‹› í•„í„°ë§ í›„: {len(candidates)}ê°œ")

    # ì œëª© íŒ¨í„´ í†µê³„
    titles = [c for c in candidates if is_table_title_like(c['text'])]
    if len(titles) >= 1:
        print(f"  ì œëª©íŒ¨í„´ í›„ë³´: {len(titles)}ê°œ (ML ê¸°ë°˜ ì ìˆ˜ ì ìš©)")

    # í•˜ë“œ í•„í„°ë§: ëª…í™•í•œ ë…¸ì´ì¦ˆë§Œ ì œê±°
    before = len(candidates)
    filtered_out = []
    kept = []
    for c in candidates:
        txt = c['text']
        # êµì°¨ ì°¸ì¡°
        if is_cross_reference(txt):
            filtered_out.append(f"{txt[:MAX_DISPLAY_TEXT_LENGTH]}... (êµì°¨ì°¸ì¡°)")
        # ê¸´ ì„¤ëª…ë¬¸ (ì¢…ê²°ì–´ë¯¸ë¡œ ëë‚¨)
        elif len(txt) >= LONG_SENTENCE_MIN_LENGTH and re.search(r"(ë‹¤|ì˜€ë‹¤|í•œë‹¤|ì˜€ë‹¤)\.$", txt.strip()):
            filtered_out.append(f"{txt[:MAX_DISPLAY_TEXT_LENGTH]}... (ê¸´ ì„¤ëª…ë¬¸)")
        else:
            kept.append(c)
    candidates = kept
    if len(candidates) != before:
        print(f"  ë…¸ì´ì¦ˆ ì œê±°: {before}â†’{len(candidates)}ê°œ")
        for fo in filtered_out[:MAX_FILTER_DISPLAY]:
            print(f"    ì œê±°: {fo}")

    if not candidates:
        print("  âŒ í•„í„°ë§ í›„ í›„ë³´ ì—†ìŒ")
        return "", None

    # Step 3: ML ê¸°ë°˜ ìŠ¤ì½”ì–´ë§
    print("\n  í›„ë³´ ì ìˆ˜:")
    scored = score_candidates_with_logits(candidates, table_ctx, table_bbox)
    for x in scored:
        t = x["text"][:MAX_DISPLAY_TEXT_LENGTH] if len(x["text"]) > MAX_DISPLAY_TEXT_LENGTH else x["text"]
        d = x["details"]
        print(f"    '{t}'")
        print(f"      reranker: {d['reranker']:.3f}, heuristic: {d.get('heuristic', 0):.3f}, Final: {x['score']:.3f}")

    # ìµœê³  ì ìˆ˜ ì„ íƒ (ë™ì ì´ë©´ ìœ„ìª½ ìš°ì„ )
    # 1ì°¨: ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ, 2ì°¨: y ì¢Œí‘œ ì˜¤ë¦„ì°¨ìˆœ (ìœ„ìª½ì´ ì‘ì€ ê°’)
    scored.sort(key=lambda x: (-x['score'], x['bbox'][1]))
    best = scored[0]

    # ìµœì¢… ê²€ì¦: í‘œ ì œëª© íŒ¨í„´ì´ë©´ ì„ê³„ê°’ ë‚®ì¶¤
    threshold = SCORE_THRESHOLD
    if is_table_title_like(best['text']):
        threshold = SCORE_THRESHOLD * 0.5  # í‘œ ì œëª© íŒ¨í„´ì€ ì ˆë°˜ ì„ê³„ê°’
        print(f"  ğŸ“‹ í‘œ ì œëª© íŒ¨í„´ ê°ì§€ â†’ ì„ê³„ê°’ ì™„í™” ({threshold:.2f})")

    if best['score'] < threshold:
        print(f"  âš ï¸  ìµœê³  ì ìˆ˜({best['score']:.3f})ê°€ ì„ê³„ê°’({threshold:.2f}) ë¯¸ë§Œ")
        return "", None

    print(f"\n  âœ… ì„ íƒ: '{best['text']}' (ì ìˆ˜: {best['score']:.3f})")
    return best['text'], best['bbox']

@app.route('/get_title', methods=['POST'])
def get_title():
    """ë°›ì€ ë°ì´í„°(tables, texts)ì— ê° í…Œì´ë¸”ë§ˆë‹¤ title í”„ë¡œí¼í‹°ë¥¼ ì¶”ê°€í•´ì„œ ë˜ëŒë ¤ì£¼ëŠ” API"""
    data = request.get_json()

    if isinstance(data, dict):
        tables = data.get('tables', [])
        texts = data.get('texts', [])

        print(f"ë°›ì€ í…Œì´ë¸” ìˆ˜: {len(tables)}")
        print(f"ë°›ì€ í…ìŠ¤íŠ¸ ìˆ˜: {len(texts)}")

        result_tables = []
        used_titles = set()

        for idx, table in enumerate(tables):
            table_with_title = copy.deepcopy(table)
            title, title_bbox = find_title_for_table(table, texts, all_tables=tables, used_titles=used_titles)
            print(f"í…Œì´ë¸” {idx} íƒ€ì´í‹€: '{title}'")
            table_with_title['title'] = title
            table_with_title['title_bbox'] = title_bbox

            if title:
                used_titles.add(title)

            result_tables.append(table_with_title)

        print(f"\nìµœì¢… ë°˜í™˜: {len(result_tables)}ê°œ í…Œì´ë¸”")
        return jsonify(result_tables)

    elif isinstance(data, list):
        result = []
        for idx, table in enumerate(data):
            table_with_title = copy.deepcopy(table)
            table_with_title['title'] = f'í…Œì´ë¸” {idx + 1}ì˜ íƒ€ì´í‹€'
            result.append(table_with_title)
        return jsonify(result)

    else:
        return jsonify({'error': 'Data must be an object with tables and texts, or an array of tables'}), 400

if __name__ == '__main__':
    app.run(host=API_HOST, port=API_PORT, debug=API_DEBUG)
