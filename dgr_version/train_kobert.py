"""
KoBERT ë¶„ë¥˜ê¸° í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
"""
import json
import os
from kobert_classifier import train_kobert_classifier, TableTextClassifier


def load_training_data_from_json(json_path):
    """JSON íŒŒì¼ì—ì„œ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    train_data = []
    for item in data['train_data']:
        text = item['text']
        label = item['label']
        train_data.append((text, label))

    print(f"âœ… í•™ìŠµ ë°ì´í„° ë¡œë“œ: {len(train_data)}ê°œ")
    return train_data


def create_sample_data():
    """ìƒ˜í”Œ í•™ìŠµ ë°ì´í„° ìƒì„± (ìµœì†Œ ì˜ˆì‹œ)"""
    train_data = [
        # 0: ì œëª©
        ("í‘œ 3.2 ì—°ê°„ ì‹¤ì ", 0),
        ("í‘œ B.8 ì›”ë³„ ê¸°ì˜¨", 0),
        ("í‘œ 4-21 ì˜ˆì‚° ì§‘í–‰ í˜„í™©", 0),
        ("â–¡ ì¶”ì§„ì¡°ì§ êµ¬ì„±", 0),
        ("â–  ì‚¬ì—…ê°œìš”", 0),
        ("ã…‡ ì£¼ìš” ì¶”ì§„ ë‚´ìš©", 0),
        ("â‘  ê¸°ë³¸ ë°©í–¥", 0),
        ("â‘¡ ì„¸ë¶€ ê³„íš", 0),
        ("(1) ì‚¬ì—… ì¶”ì§„ ë°©í–¥", 0),
        ("1) ì¶”ì§„ ë°°ê²½", 0),
        ("3.2 í† ì§€ì´ìš©í˜„í™©", 0),
        ("4.1.2 ì¡°ì‚¬ ë°©ë²•", 0),
        ("í‘œ A.6 í™˜ê²½ì˜í–¥í‰ê°€", 0),
        ("í‘œ 5.1 ì¬ë¬´ í˜„í™©", 0),
        ("â—† ì¶”ì§„ ì „ëµ", 0),
        ("â‘¢ ì„¸ë¶€ ì‹¤í–‰ê³„íš", 0),
        ("2) ì£¼ìš” ë‚´ìš©", 0),
        ("í‘œ C.12 ì‚¬ì—…ë¹„ ë‚´ì—­", 0),
        ("5.3 ìš´ì˜ ë°©ì•ˆ", 0),
        ("â–¡ ê¸°ëŒ€ íš¨ê³¼", 0),

        # 1: ì„¤ëª…
        ("ìƒì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒ í‘œ B.12ì™€ ê°™ë‹¤", 1),
        ("í‘œ A.20ì— ì˜í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤", 1),
        ("í‘œ 3.2ì—ì„œ ë‚˜íƒ€ë‚œ ë°”ì™€ ê°™ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ë¥¼ ë³´ì¸ë‹¤", 1),
        ("â€» ë³¸ ìë£ŒëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤", 1),
        ("â€» ìƒê¸° ë‚´ìš©ì€ ë³€ê²½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤", 1),
        ("ë³¸ í‘œëŠ” 2023ë…„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, í–¥í›„ ë³€ë™ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤", 1),
        ("ì•„ë˜ í‘œì—ì„œ ë³´ëŠ” ë°”ì™€ ê°™ì´ ì „ë…„ ëŒ€ë¹„ ì¦ê°€í•˜ì˜€ë‹¤", 1),
        ("ë‹¤ìŒ í‘œ 5.1ì— ë”°ë¥´ë©´ ë§¤ì¶œì´ ì¦ê°€í–ˆë‹¤", 1),
        ("í‘œ B.4ì—ì„œì™€ ê°™ì´ ë¶„ê¸°ë³„ ì‹¤ì ì„ ë‚˜íƒ€ë‚¸ë‹¤", 1),
        ("â€» 2024ë…„ 1ì›” ê¸°ì¤€", 1),
        ("ìƒê¸° í‘œì— ë‚˜íƒ€ë‚œ ìˆ˜ì¹˜ëŠ” ì ì •ì¹˜ì…ë‹ˆë‹¤", 1),
        ("ì•„ë˜ í‘œëŠ” ìµœê·¼ 3ë…„ê°„ì˜ ì¶”ì´ë¥¼ ë³´ì—¬ì¤€ë‹¤", 1),
        ("ë³¸ ìë£ŒëŠ” ë‚´ë¶€ ê²€í† ìš©ìœ¼ë¡œ ì™¸ë¶€ ê³µê°œë¥¼ ê¸ˆí•©ë‹ˆë‹¤", 1),
        ("ë‹¤ìŒ í‘œ A.8ì„ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤", 1),

        # 2: ì œëª©ì•„ë‹˜
        ("123", 2),
        ("45", 2),
        ("Â© 2024 All Rights Reserved", 2),
        ("ë‹¨ìœ„: â„ƒ", 2),
        ("ë‹¨ìœ„: %", 2),
        ("[ë‹¨ìœ„ : mm]", 2),
        ("(ë‹¨ìœ„: ë°±ë§Œì›)", 2),
        ("-", 2),
        ("...", 2),
        ("1", 2),
        ("99", 2),
        ("unit: kg", 2),
        ("â„ƒ", 2),
        ("%)", 2),
        ("Copyright 2024", 2),
        ("---", 2),
        ("Â·", 2),
        ("â€»", 2),
    ]

    return train_data


def main():
    """í•™ìŠµ ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("KoBERT í‘œ í…ìŠ¤íŠ¸ ë¶„ë¥˜ê¸° í•™ìŠµ")
    print("=" * 60)

    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
    script_dir = os.path.dirname(os.path.abspath(__file__))

    # ì˜µì…˜ 1: JSON íŒŒì¼ì—ì„œ ë¡œë“œ
    json_path = os.path.join(script_dir, 'train_data_example.json')
    train_data = load_training_data_from_json(json_path)

    # ì˜µì…˜ 2: ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© (ì£¼ì„ ì²˜ë¦¬)
    # train_data = create_sample_data()

    # ë°ì´í„° ì¼ë¶€ë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©, ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)
    # train_data = train_data[:1000]  # ì²˜ìŒ 1000ê°œë§Œ ì‚¬ìš©

    print(f"\nğŸ“Š í•™ìŠµ ë°ì´í„° í†µê³„:")
    labels_count = {0: 0, 1: 0, 2: 0}
    for _, label in train_data:
        labels_count[label] += 1

    print(f"  ì œëª©: {labels_count[0]}ê°œ")
    print(f"  ì„¤ëª…: {labels_count[1]}ê°œ")
    print(f"  ì œëª©ì•„ë‹˜: {labels_count[2]}ê°œ")
    print(f"  ì´í•©: {len(train_data)}ê°œ")

    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    epochs = 2  # ì¶”ê°€ í•™ìŠµì‹œ 1-2 ì—í­ìœ¼ë¡œ ì¶©ë¶„ (ì²˜ìŒ í•™ìŠµì€ 5-10)
    batch_size = 8  # ë°°ì¹˜ í¬ê¸° (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ)
    lr = 1e-5  # ì¶”ê°€ í•™ìŠµì‹œ ë‚®ì€ í•™ìŠµë¥  ê¶Œì¥ (ì²˜ìŒ í•™ìŠµì€ 2e-5)
    save_path = os.path.join(script_dir, 'kobert_table_classifier.pt')

    # ì¶”ê°€ í•™ìŠµì„ ìœ„í•œ ê¸°ì¡´ ëª¨ë¸ ê²½ë¡œ (Noneì´ë©´ ì²˜ìŒë¶€í„° í•™ìŠµ)
    pretrained_model = os.path.join(script_dir, 'kobert_table_classifier.pt')  # ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©
    # pretrained_model = None  # ì²˜ìŒë¶€í„° í•™ìŠµí•˜ë ¤ë©´ Noneìœ¼ë¡œ ì„¤ì •

    print(f"\nâš™ï¸  í•™ìŠµ íŒŒë¼ë¯¸í„°:")
    print(f"  ì—í­: {epochs}")
    print(f"  ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"  í•™ìŠµë¥ : {lr}")
    print(f"  ì €ì¥ ê²½ë¡œ: {save_path}")
    if pretrained_model:
        print(f"  ê¸°ì¡´ ëª¨ë¸: {pretrained_model} (ì¶”ê°€ í•™ìŠµ)")
    else:
        print(f"  ê¸°ì¡´ ëª¨ë¸: ì—†ìŒ (ì²˜ìŒë¶€í„° í•™ìŠµ)")

    # í•™ìŠµ ì‹¤í–‰
    train_kobert_classifier(
        train_data=train_data,
        val_data=None,  # ê²€ì¦ ë°ì´í„° ìˆìœ¼ë©´ ì¶”ê°€
        epochs=epochs,
        batch_size=batch_size,
        lr=lr,
        save_path=save_path,
        pretrained_model_path=pretrained_model  # ê¸°ì¡´ ëª¨ë¸ ê²½ë¡œ ì „ë‹¬
    )

    # í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 60)
    print("í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    classifier = TableTextClassifier(model_path=save_path)

    test_cases = [
        "í‘œ 4.21 ì˜ˆì‚° ì§‘í–‰ í˜„í™©",
        "â–¡ ì¶”ì§„ ì¡°ì§ êµ¬ì„±",
        "ã…‡ ì‚¬ì—… ê°œìš”",
        "â‘  ì£¼ìš” ë‚´ìš©",
        "ìƒì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒ í‘œì™€ ê°™ë‹¤",
        "í‘œ A.20ì— ì˜í•˜ë©´ ì¦ê°€ ì¶”ì„¸ë¥¼ ë³´ì¸ë‹¤",
        "â€» ë³¸ ìë£ŒëŠ” ì°¸ê³ ìš©ì…ë‹ˆë‹¤",
        "123",
        "ë‹¨ìœ„: â„ƒ",
        "Â© 2024 All Rights Reserved",
    ]

    print("\nğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    for text in test_cases:
        label, prob, all_probs = classifier.predict(text, return_probs=True)
        print(f"\n'{text}'")
        print(f"  â†’ ì˜ˆì¸¡: {label} (í™•ì‹ ë„: {prob:.3f})")
        print(f"  ìƒì„¸: ì œëª©={all_probs[0]:.3f}, ì„¤ëª…={all_probs[1]:.3f}, ì œëª©ì•„ë‹˜={all_probs[2]:.3f}")


if __name__ == '__main__':
    main()
